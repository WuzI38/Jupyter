{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMCHFWiDJp8czCB3R8Rs3AR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WuzI38/Data/blob/Jupyter/MidiGen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Second attempt on music generation"
      ],
      "metadata": {
        "id": "ZY6KpIEZ_Oi3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download data"
      ],
      "metadata": {
        "id": "6CmoA837DeWP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q kaggle"
      ],
      "metadata": {
        "id": "BUx4f1NZAfRS"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SKvpUgaAn53",
        "outputId": "3fc42323-1ffe-4c31-c325-28b701e117c1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp /content/gdrive/MyDrive/Kaggle/kaggle.json ~/.kaggle/\n",
        "!chmod 600 /root/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "tWJVCAc3BTed"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download programgeek01/anime-music-midi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCUGX-H7Dah0",
        "outputId": "53841b9f-17a8-461e-e2d8-626ae9cbaa21"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "anime-music-midi.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzip data\n",
        "import zipfile\n",
        "\n",
        "zip_ref = zipfile.ZipFile(\"anime-music-midi.zip\", \"r\") # Hey, don't blame me for the name, I am not this dataset's creator\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "_eVX_xi7Dg1f"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# enables music21 to render images of musical notes\n",
        "print('installing lilypond...')\n",
        "!apt-get install lilypond > /dev/null\n",
        "\n",
        "# enables playing midi files\n",
        "print('installing fluidsynth...')\n",
        "!apt-get install fluidsynth > /dev/null\n",
        "\n",
        "# Copy soundfont to content directory\n",
        "!cp /usr/share/sounds/sf2/FluidR3_GM.sf2 ./font.sf2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KBtibLzDs3n",
        "outputId": "0aa86622-4c66-4a13-ed17-38db625f3e24"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "installing lilypond...\n",
            "installing fluidsynth...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading and preprocessing"
      ],
      "metadata": {
        "id": "biyx9idHD_e3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parsing files"
      ],
      "metadata": {
        "id": "QqWG_Bz1EINe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from music21 import *\n",
        "from fractions import Fraction\n",
        "\n",
        "path = \"/content/data/undertale/\"\n",
        "midi_list = []\n",
        "for filename in os.listdir(path):\n",
        "  # print(filename)\n",
        "  parsed_file = converter.parse(path + filename)\n",
        "  midi_list.append(parsed_file)"
      ],
      "metadata": {
        "id": "6MaDbh8_EKjP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "midi_list[0]"
      ],
      "metadata": {
        "id": "TP5OKnpQEMro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extracting notes and chords\n",
        "\n"
      ],
      "metadata": {
        "id": "Rvsia1LdJYcz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import music21\n",
        "def fragmentise(midi_stream: music21.stream.Score) -> list:\n",
        "  return [part.flat.notes for part in midi_stream.parts]"
      ],
      "metadata": {
        "id": "nYSX6tC8PQu6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def signature(midi_stream: music21.stream.Score) -> list:\n",
        "  sig = midi_stream.getTimeSignatures()[0]\n",
        "  return [sig.numerator, sig.denominator]"
      ],
      "metadata": {
        "id": "Qsvr_VhQQnBN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frag = fragmentise(midi_list[2])\n",
        "frag"
      ],
      "metadata": {
        "id": "hQcUMS4TLYep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sg = signature(frag[0])\n",
        "sg"
      ],
      "metadata": {
        "id": "xVsAdaJ_Qb8T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Part one - extract notes from both streams and save them into a list\n",
        "def get_all_notes(midi_piece: music21.stream.Score) -> list:\n",
        "  all_notes = list()\n",
        "  note_types = set()\n",
        "  midi_part = fragmentise(midi_piece)[0] # use only notes that belong to main melody\n",
        "  for nt in midi_part.flat.notes: \n",
        "    if isinstance(nt, note.Note):\n",
        "      pitch = str(max(0.0, nt.pitch.ps))\n",
        "    elif isinstance(nt, chord.Chord):\n",
        "      pitch = sorted([str(max(0.0, n.ps)) for n in nt.pitches])\n",
        "      pitch = ' '.join(pitch)\n",
        "    ql = nt.duration.quarterLength\n",
        "    all_notes.append([nt.offset, pitch, ql if ql > 0.0 else 0.25]) # If for some reason len is 0 replace it with 0.25\n",
        "  return all_notes\n",
        "  \n",
        "notes_list = get_all_notes(midi_list[1])\n",
        "notes_list[:10]"
      ],
      "metadata": {
        "id": "wJfX8VwCWGLE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Part 2 extract all chord types from the dataset\n",
        "import numpy as np\n",
        "\n",
        "def get_chord_types(dataset: list) -> dict:\n",
        "  chord_types = dict()\n",
        "  for d in dataset:\n",
        "    notes_list = np.array(get_all_notes(d))\n",
        "    strings = notes_list[:, 1]\n",
        "    for s in strings:\n",
        "      chord_types[s] = 1 + chord_types[s] if chord_types.get(s) is not None else 1\n",
        "  return chord_types\n",
        "\n",
        "types = get_chord_types(midi_list)"
      ],
      "metadata": {
        "id": "n9emf8arWo4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(types))"
      ],
      "metadata": {
        "id": "Im4dtrGwcjUb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Counting invidual chords and removing the rare ones"
      ],
      "metadata": {
        "id": "fk7Iyf_tfbzr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chord_counts = dict()\n",
        "for item in sorted(list(types.values())):\n",
        "  chord_counts[str(item)] = 1 + chord_counts[str(item)] if chord_counts.get(str(item)) is not None else 1\n",
        "\n",
        "chord_counts = {k: v for k, v in chord_counts.items() if v > 1}"
      ],
      "metadata": {
        "id": "VfX3UuRzfxKM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the values\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Extract the keys and values from the dictionary as lists\n",
        "keys = list(chord_counts.keys())\n",
        "values = list(chord_counts.values())\n",
        "\n",
        "# Change size\n",
        "plt.figure(figsize=(16, 12))\n",
        "\n",
        "# Create a bar chart using the plot function\n",
        "plt.bar(keys, values)\n",
        "\n",
        "# Add a title and axis labels\n",
        "plt.title('Number of types among chords with the same popularity (only values > 1)')\n",
        "plt.xlabel('Popularity')\n",
        "plt.ylabel('Types')\n",
        "\n",
        "# Rotate labels\n",
        "plt.xticks(rotation=90)\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "N-qqcFaJeLsr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from statistics import mean\n",
        "HOW_MANY = 20\n",
        "means = [mean([len(k)//4 for k, v in types.items() if v <= i]) for i in range(1, HOW_MANY + 1)]"
      ],
      "metadata": {
        "id": "Bx29u1RklvNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the means\n",
        "plt.figure(figsize=(10, 7))\n",
        "\n",
        "# Create a bar chart using the plot function\n",
        "plt.bar(list(range(1, HOW_MANY + 1)), means)\n",
        "\n",
        "# Add a title and axis labels\n",
        "plt.title('Avg length of rare chords')\n",
        "plt.xlabel('Popularity of a chord')\n",
        "plt.ylabel('Avg length')\n",
        "\n",
        "# Rotate labels\n",
        "plt.xticks(rotation=90)\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8uXOIKobmiLl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The avg length is around 3 for the rare chords, so I can probably shorten them to 2 notes for the encoding purposes, so i don't have to use 1881 different values"
      ],
      "metadata": {
        "id": "zj9AyFwHo3yl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualize melodies"
      ],
      "metadata": {
        "id": "VtYKuLXOo31g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import music21\n",
        "from IPython.display import Image, Audio\n",
        "\n",
        "def show(music):\n",
        "  display(Image(str(music.write('lily.png'))))\n",
        "\n",
        "def play(music):\n",
        "    try:\n",
        "        filename = music.write('mid')\n",
        "        os.system(f'fluidsynth -ni font.sf2 {filename} -F {filename}.wav -r 16000 > /dev/null')\n",
        "        display(Audio(f'{filename}.wav'))\n",
        "    except Exception as e:\n",
        "        print(f'Error: {e}')"
      ],
      "metadata": {
        "id": "LuD7JsX2pAJK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n = music21.note.Note('D#3')\n",
        "n.duration = duration.Duration(Fraction(1, 3))\n",
        "show(n)"
      ],
      "metadata": {
        "id": "7WmhlpMZpBOz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "play(n)"
      ],
      "metadata": {
        "id": "voGuiWp0pFu7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from music21 import chord\n",
        "def create_midi_part(part_n: music21.stream.Score) -> list:\n",
        "  melody = get_all_notes(part_n)\n",
        "  melody_ready = []\n",
        "  # Create really ugly and unnecessary for loop just for \n",
        "  for sound in melody:\n",
        "    if len(sound[1]) <= 4:\n",
        "      new_note = note.Note(int(float(sound[1])), quarterLength = sound[2]) # use .nameWithOctave for the names only\n",
        "    else:\n",
        "      pitches_str = sound[1].split()\n",
        "      pitches = [int(float(s)) for s in pitches_str]\n",
        "      new_note = chord.Chord(pitches, quarterLength = sound[2]) # Must be an int (despite the fact that GPT says otherwise)\n",
        "    new_note.offset = sound[0]\n",
        "    melody_ready.append(new_note)\n",
        "  return melody_ready"
      ],
      "metadata": {
        "id": "CPf_ZZv2pK6K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "melody_visual = create_midi_part(midi_list[15])\n",
        "melody_midi = stream.Stream(melody_visual)"
      ],
      "metadata": {
        "id": "oq28LGoFqbHX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show(melody_midi[:50])"
      ],
      "metadata": {
        "id": "38AazfGFziVS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "play(melody_midi[:50])"
      ],
      "metadata": {
        "id": "JjJTfPU7zqoA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simpifying chords and encoding"
      ],
      "metadata": {
        "id": "VfSF6AcsdpOD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LIMIT = 8\n",
        "TRIM_TO = 9\n",
        "TRIM_TO = TRIM_TO if (TRIM_TO - 4) % 5 == 0 else 9 # Choose correct trim\n",
        "\n",
        "### Check if removing rare chords helps\n",
        "ENCODER = dict() # checking if trimming chords makes any sense at all + creating id for each chord\n",
        "TRIMMER = dict() # enables transformation of chords\n",
        "id = 2\n",
        "for key, value in types.items(): \n",
        "  kcp = key[:TRIM_TO] if value <= LIMIT and len(key) > TRIM_TO else key\n",
        "  TRIMMER[key] = kcp\n",
        "  if ENCODER.get(kcp) is None:\n",
        "    ENCODER[kcp] = id\n",
        "    id += 1\n",
        "\n",
        "print(len(types), len(ENCODER))"
      ],
      "metadata": {
        "id": "qjMQBTaQeNnV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Encoding and decoding"
      ],
      "metadata": {
        "id": "B4yL-XwsnkAw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "notes_list[:10]"
      ],
      "metadata": {
        "id": "2MfJdONqjY5m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Warning!!! This method removes rare chords, so the encoded version may not be the same\n",
        "# Pause id -> pause, empty_id -> no new notes\n",
        "\n",
        "def encode_part(notes: list, chord_trans: dict, chords_id: dict, empty_id: int = 1, pause_id: int = 0) -> list:\n",
        "  sound_list = list()\n",
        "  for index, value in enumerate(notes[:-1]):\n",
        "    cnt = int(value[2] * 12)\n",
        "    offest_dif = int(12 * (notes[index + 1][0] - value[0]))\n",
        "    for x in range(cnt):\n",
        "      new_symbol = chords_id[chord_trans[value[1]]] if not x else empty_id\n",
        "      sound_list.append(new_symbol)\n",
        "    for _ in range(max(offest_dif - cnt, 0)):\n",
        "      sound_list.append(pause_id)\n",
        "  cnt = int(notes[-1][2] * 12)\n",
        "  for x in range(cnt):\n",
        "      new_symbol = chords_id[chord_trans[notes[-1][1]]] if not x else empty_id\n",
        "      sound_list.append(new_symbol)\n",
        "  return sound_list"
      ],
      "metadata": {
        "id": "LyJwNU6Da0yi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "part_encoded = encode_part(get_all_notes(midi_list[1]), TRIMMER, ENCODER)\n",
        "part_encoded[:20]"
      ],
      "metadata": {
        "id": "A83MdBaEeHrm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Simply transform notes of len 1/3 into python fractions\n",
        "def float_to_fraction(x: float):\n",
        "    frac = Fraction(x).limit_denominator()\n",
        "    return frac if (frac.denominator % 3 == 0 and frac.numerator % frac.denominator != 0) else x\n",
        "\n",
        "print(float_to_fraction(0.25), float_to_fraction(0.3333333333333))"
      ],
      "metadata": {
        "id": "N_XgkaFIuxXx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_part(encoded: list, chords_id_encoder: dict, empty_id: int = 1, pause_id: int = 0) -> list:\n",
        "  notes_decoded = list()\n",
        "  counter = 1\n",
        "  zero_counter = 0\n",
        "  offset = 0\n",
        "  last_n = encoded[0]\n",
        "  for n in encoded[1:]:\n",
        "    if n not in (empty_id, pause_id):\n",
        "      notes_decoded.append([offset, chords_id_encoder[last_n], float_to_fraction(counter/12)])\n",
        "      offset += float((counter + zero_counter) / 12)\n",
        "      counter = 1\n",
        "      zero_counter = 0\n",
        "      last_n = n\n",
        "    elif n == empty_id:\n",
        "      counter += 1\n",
        "    elif n == pause_id:\n",
        "      zero_counter += 1\n",
        "  notes_decoded.append([offset, chords_id_encoder[last_n], float_to_fraction(counter/12)])\n",
        "      \n",
        "  return notes_decoded"
      ],
      "metadata": {
        "id": "lYk1atWZeukS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DECODER = {v: k for k, v in ENCODER.items()}\n",
        "lst = decode_part(part_encoded, DECODER)\n",
        "lst[:10]"
      ],
      "metadata": {
        "id": "LQlB1ltEkVf8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Warning: there is a certain issue if it comes to midi files. Sometimes 2 separate notes which do not belong to a chord have the same offsets - in that case the offset of the second note is shifted by its length"
      ],
      "metadata": {
        "id": "0XDwf0GqjqzS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Windowing + one hot encoding\n",
        "As chords and notes are discrete values, one hot encoding might be a good idea ???\n",
        "As octaves are represented in my encoding as 48 values (4 quarter notes are represented by 12 digits) the horizon value will be "
      ],
      "metadata": {
        "id": "i7bbzlzAk8gS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Windowing"
      ],
      "metadata": {
        "id": "oltyMp85-c9T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# As \n",
        "HORIZON = 12\n",
        "WINDOW_SIZE = 48"
      ],
      "metadata": {
        "id": "UeQLP-sIgLFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create function to label windowed data\n",
        "def get_labelled_windows(x: np.ndarray, horizon=12):\n",
        "  return x[:, :-horizon], x[:, -horizon:]"
      ],
      "metadata": {
        "id": "s-y9qQiSyxYj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_windows(x: np.ndarray, window_size: int = WINDOW_SIZE, horizon: int = HORIZON) -> np.ndarray:\n",
        "  # 1. Create a window of specific window size (add the horizon on the end for labelling later)\n",
        "  window_step = np.expand_dims(np.arange(window_size + horizon), axis=0)\n",
        "\n",
        "  # 2. Use numpy indexing to create a 2D array of multiple windows\n",
        "  window_indexes = window_step + np.expand_dims(np.arange(len(x)-(window_size+horizon-1)), axis=0).transpose()\n",
        "  # len(x)-(window_size+horizon-1) is used to prevent sliding window from getting out of range\n",
        "  # Basically for some reason the sum of [[0, 1, 2]] and [[0], [1], [2]] gives you [[0, 1, 2], [1, 2, 3], [2, 3, 4]]\n",
        "\n",
        "  # 3. Index on the target array (a time series) with 2D array of multiple window steps\n",
        "  windowed_array = x[window_indexes]\n",
        "\n",
        "  # 4. Get the labelled windows\n",
        "  windows, labels = get_labelled_windows(windowed_array, horizon=horizon)\n",
        "\n",
        "  return windows, labels"
      ],
      "metadata": {
        "id": "YRNTN4FE3PCJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_windows, test_labels = make_windows(np.array(part_encoded), window_size=WINDOW_SIZE, horizon=HORIZON)"
      ],
      "metadata": {
        "id": "XA1E5kz37UBI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_windows[:5]"
      ],
      "metadata": {
        "id": "FKFv0icb8etE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_labels[:5]"
      ],
      "metadata": {
        "id": "XVk3hDdE9cQD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Joining, one hot encoding the dataset and creating train/test split"
      ],
      "metadata": {
        "id": "hqT1NGQA-ffy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Joining and creating splits"
      ],
      "metadata": {
        "id": "thmtNUk9OTcc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The function removes pieces shorter than 40 notes by default - I assume there are not very important for the whole dataset. The function does not work properly if the piece given as an argument is shorter than 5 quarter notes"
      ],
      "metadata": {
        "id": "dAdTyKPcM0lV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_TEST = 0.8\n",
        "\n",
        "def join_midis(midi_list: list, \n",
        "               trimmer: dict, \n",
        "               encoder: dict, \n",
        "               train_test: np.float128 = TRAIN_TEST,\n",
        "               empty_id: int = 1, \n",
        "               pause_id: int = 0,\n",
        "               window_size: int = WINDOW_SIZE, \n",
        "               horizon: int = HORIZON,\n",
        "               shortest_piece: int = 40) -> np.ndarray:\n",
        "  \n",
        "  X_train = None\n",
        "  y_train = None\n",
        "  X_test = None\n",
        "  y_test = None\n",
        "  \n",
        "  for midi in midi_list:\n",
        "    notes = get_all_notes(midi)\n",
        "    if len(notes) < shortest_piece:\n",
        "      continue\n",
        "    divider = int(TRAIN_TEST * len(notes))\n",
        "    train, test = notes[:divider], notes[divider:]\n",
        "\n",
        "    train_part_encoded = encode_part(train, trimmer, encoder)\n",
        "    test_part_encoded = encode_part(test, trimmer, encoder)\n",
        "\n",
        "    train_windows, train_labels = make_windows(np.array(train_part_encoded), window_size, horizon)\n",
        "    test_windows, test_labels = make_windows(np.array(test_part_encoded), window_size, horizon)\n",
        "\n",
        "    if X_train is None:\n",
        "      X_train = train_windows\n",
        "      y_train = train_labels\n",
        "      X_test = test_windows\n",
        "      y_test = test_labels\n",
        "    else:\n",
        "      X_train = np.concatenate([X_train, train_windows])\n",
        "      y_train = np.concatenate([y_train, train_labels])\n",
        "      X_test = np.concatenate([X_test, test_windows])\n",
        "      y_test = np.concatenate([y_test, test_labels])\n",
        "\n",
        "  return X_train, y_train, X_test, y_test"
      ],
      "metadata": {
        "id": "TKyGRzjs_G9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train, X_test, y_test = join_midis(midi_list, TRIMMER, ENCODER)"
      ],
      "metadata": {
        "id": "haG3oEiAI9-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### One hot encoding"
      ],
      "metadata": {
        "id": "ke1hN3W4OW_F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "LvUW9Y-7OQyl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pVNPmzrWVDI5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}